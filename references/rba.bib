@article{chenHandlingMultiplicityNeuroimaging2019,
	title = {Handling {Multiplicity} in {Neuroimaging} through {Bayesian} {Lenses} with {Multilevel} {Modeling}},
	volume = {17},
	copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
	issn = {1539-2791},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6635105/},
	doi = {10.1007/s12021-018-9409-6},
	abstract = {Here we address the current issues of inefficiency and over-penalization in the massively univariate approach followed by the correction for multiple testing, and propose a more efficient model that pools and shares information among brain regions. Using Bayesian multilevel (BML) modeling, we control two types of error that are more relevant than the conventional false positive rate (FPR): incorrect sign (type S) and incorrect magnitude (type M). BML also aims to achieve two goals: 1) improving modeling efficiency by having one integrative model and thereby dissolving the multiple testing issue, and 2) turning the focus of conventional null hypothesis significant testing (NHST) on FPR into quality control by calibrating type S errors while maintaining a reasonable level of inference efficiency. The performance and validity of this approach are demonstrated through an application at the region of interest (ROI) level, with all the regions on an equal footing: unlike the current approaches under NHST, small regions are not disadvantaged simply because of their physical size. In addition, compared to the massively univariate approach, BML may simultaneously achieve increased spatial specificity and inference efficiency, and promote results reporting in totality and transparency. The benefits of BML are illustrated in performance and quality checking using an experimental dataset. The methodology also avoids the current practice of sharp and arbitrary thresholding in the p-value funnel to which the multidimensional data are reduced. The BML approach with its auxiliary tools is available as part of the AFNI suite for general use.},
	number = {4},
	urldate = {2020-10-01},
	journal = {Neuroinformatics},
	author = {Chen, Gang and Xiao, Yaqiong and Taylor, Paul A. and Rajendra, Justin K. and Riggins, Tracy and Geng, Fengji and Redcay, Elizabeth and Cox, Robert W.},
	month = oct,
	year = {2019},
	pmid = {30649677},
	pmcid = {PMC6635105},
	pages = {515--545},
	file = {Chen et al. - 2019 - Handling Multiplicity in Neuroimaging through Baye.pdf:/Users/gangchen/Zotero/storage/862G5MWE/Chen et al. - 2019 - Handling Multiplicity in Neuroimaging through Baye.pdf:application/pdf},
}

@article{carpenterStanProbabilisticProgramming2017,
	title = {Stan: {A} {Probabilistic} {Programming} {Language}},
	volume = {76},
	copyright = {Copyright (c) 2017 Bob Carpenter, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, Allen Riddell},
	issn = {1548-7660},
	shorttitle = {Stan},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v076i01},
	doi = {10.18637/jss.v076.i01},
	language = {en},
	number = {1},
	urldate = {2020-10-31},
	journal = {Journal of Statistical Software},
	author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
	month = jan,
	year = {2017},
	note = {Number: 1},
	keywords = {Bayesian inference, algorithmic differentiation, probabilistic programming, Stan},
	pages = {1--32},
	file = {Full Text:/Users/gangchen/Zotero/storage/FN4W8IJP/Carpenter et al. - 2017 - Stan A Probabilistic Programming Language.pdf:application/pdf;Snapshot:/Users/gangchen/Zotero/storage/LMBW968W/v076i01.html:text/html},
}

@article{burknerBrmsPackageBayesian2017,
	title = {brms: {An} {R} {Package} for {Bayesian} {Multilevel} {Models} {Using} {Stan}},
	volume = {80},
	copyright = {Copyright (c) 2017 Paul-Christian Bürkner},
	issn = {1548-7660},
	shorttitle = {brms},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v080i01},
	doi = {10.18637/jss.v080.i01},
	language = {en},
	number = {1},
	urldate = {2020-10-31},
	journal = {Journal of Statistical Software},
	author = {Bürkner, Paul-Christian},
	month = aug,
	year = {2017},
	note = {Number: 1},
	keywords = {R, Bayesian inference, Stan, MCMC, multilevel model, ordinal data},
	pages = {1--28},
	file = {Full Text:/Users/gangchen/Zotero/storage/EILPSWA7/Bürkner - 2017 - brms An R Package for Bayesian Multilevel Models .pdf:application/pdf;Snapshot:/Users/gangchen/Zotero/storage/LW3M4CEA/v080i01.html:text/html;Snapshot:/Users/gangchen/Zotero/storage/9YVTDZ6U/v080i01.html:text/html},
}

@misc{capretto2020,
    title={Bambi: A simple interface for fitting Bayesian linear models in Python},
    author={Tomás Capretto and Camen Piho and Ravin Kumar and Jacob Westfall and Tal Yarkoni and Osvaldo A. Martin},
    year={2020},
    eprint={2012.10754},
    archivePrefix={arXiv},
    primaryClass={stat.CO}
}

@article{Salvatier2016,
  doi = {10.7717/peerj-cs.55},
  url = {https://doi.org/10.7717/peerj-cs.55},
  year  = {2016},
  month = {apr},
  publisher = {{PeerJ}},
  volume = {2},
  pages = {e55},
  author = {John Salvatier and Thomas V. Wiecki and Christopher Fonnesbeck},
  title = {Probabilistic programming in Python using {PyMC}3},
  journal = {{PeerJ} Computer Science}
}

@article{chen_sources_2022,
        title = {Sources of {Information} {Waste} in {Neuroimaging}: {Mishandling} {Structures}, {Thinking} {Dichotomously}, and {Over}-{Reducing} {Data}},
        volume = {2021},
        shorttitle = {Sources of {Information} {Waste} in {Neuroimaging}},
        url = {https://apertureneuropub.cloud68.co/articles/46},
        doi = {10.52294/2e179dbf-5e37-4338-a639-9ceb92b055ea},
        abstract = {Neuroimaging relies on separate statistical inferences at tens of thousands of spatial locations. Such massively univariate analysis typically requires an adjustment for multiple testing in an attempt to maintain the family-wise error rate at a nominal level of 5\%. First, we examine three sources of substantial information loss that are associated with the common practice under the massively univariate framework: (a) the hierarchical data structures (spatial units and trials) are not well maintained in the modeling process; (b) the adjustment for multiple testing leads to an artificial step of strict thresholding; (c) information is excessively reduced during both modeling and result reporting. These sources of information loss have far-reaching impacts on result interpretability as well as reproducibility in neuroimaging. Second, to improve inference efficiency, predictive accuracy, and generalizability, we propose a Bayesian multilevel modeling framework that closely characterizes the data hierarchies across spatial units and experimental trials. Rather than analyzing the data in a way that first creates multiplicity and then resorts to a post hoc solution to address them, we suggest directly incorporating the cross-space information into one single model under the Bayesian framework (so there is no multiplicity issue). Third, regardless of the modeling framework one adopts, we make four actionable suggestions to alleviate information waste and to improve reproducibility: (1) model data hierarchies, (2) quantify effects, (3) abandon strict dichotomization, and (4) report full results. We provide examples for all of these points using both demo and real studies, including the recent Neuroimaging Analysis Replication and Prediction Study (NARPS).},
        number = {5},
        urldate = {2022-07-14},
        journal = {Aperture Neuro},
        author = {Chen, Gang and Taylor, Paul A. and Stoddard, Joel and Cox, Robert W. and Bandettini, Peter A. and Pessoa, Luiz},
        month = mar,
        year = {2022},
        pages = {46},
}

@article{wakeman_multi-subject_2015,
        title = {A multi-subject, multi-modal human neuroimaging dataset},
        volume = {2},
        issn = {2052-4463},
        url = {http://www.nature.com/articles/sdata20151},
        doi = {10.1038/sdata.2015.1},
        language = {en},
        number = {1},
        urldate = {2022-07-14},
        journal = {Scientific Data},
        author = {Wakeman, Daniel G and Henson, Richard N},
        month = dec,
        year = {2015},
        pages = {150001},
        file = {Full Text:C\:\\Users\\Lea\\Zotero\\storage\\CHTRFGTN\\Wakeman and Henson - 2015 - A multi-subject, multi-modal human neuroimaging da.pdf:application/pdf},
}

@article{esteban_fmriprep_2019,
        title = {{fMRIPrep}: a robust preprocessing pipeline for functional {MRI}},
        volume = {16},
        copyright = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
        issn = {1548-7105},
        shorttitle = {{fMRIPrep}},
        url = {https://www.nature.com/articles/s41592-018-0235-4},
        doi = {10.1038/s41592-018-0235-4},
        abstract = {Preprocessing of functional magnetic resonance imaging (fMRI) involves numerous steps to clean and standardize the data before statistical analysis. Generally, researchers create ad hoc preprocessing workflows for each dataset, building upon a large inventory of available tools. The complexity of these workflows has snowballed with rapid advances in acquisition and processing. We introduce fMRIPrep, an analysis-agnostic tool that addresses the challenge of robust and reproducible preprocessing for fMRI data. fMRIPrep automatically adapts a best-in-breed workflow to the idiosyncrasies of virtually any dataset, ensuring high-quality preprocessing without manual intervention. By introducing visual assessment checkpoints into an iterative integration framework for software testing, we show that fMRIPrep robustly produces high-quality results on a diverse fMRI data collection. Additionally, fMRIPrep introduces less uncontrolled spatial smoothness than observed with commonly used preprocessing tools. fMRIPrep equips neuroscientists with an easy-to-use and transparent preprocessing workflow, which can help ensure the validity of inference and the interpretability of results.},
        language = {en},
        number = {1},
        urldate = {2021-03-20},
        journal = {Nature Methods},
        author = {Esteban, Oscar and Markiewicz, Christopher J. and Blair, Ross W. and Moodie, Craig A. and Isik, Ayse Ilkay and Erramuzpe, Asier and Kent, James D. and Goncalves, Mathias and DuPre, Elizabeth and Snyder, Madeleine and Oya, Hiroyuki and Ghosh, Satrajit S. and Wright, Jessey and Durnez, Joke and Poldrack, Russell A. and Gorgolewski, Krzysztof J.},
        month = jan,
        year = {2019},
        note = {Number: 1
Publisher: Nature Publishing Group},
        pages = {111--116},
        file = {Full Text PDF:C\:\\Users\\Lea\\Zotero\\storage\\53XJ2E8I\\Esteban et al. - 2019 - fMRIPrep a robust preprocessing pipeline for func.pdf:application/pdf;Snapshot:C\:\\Users\\Lea\\Zotero\\storage\\UV3W6RIP\\s41592-018-0235-4.html:text/html},
}

@article{waller_enigma_2022,
        title = {{ENIGMA} {HALFpipe}: {Interactive}, reproducible, and efficient analysis for resting-state and task-based {fMRI} data},
        volume = {43},
        issn = {1097-0193},
        shorttitle = {{ENIGMA} {HALFpipe}},
        url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.25829},
        doi = {10.1002/hbm.25829},
        abstract = {The reproducibility crisis in neuroimaging has led to an increased demand for standardized data processing workflows. Within the ENIGMA consortium, we developed HALFpipe (Harmonized Analysis of Functional MRI pipeline), an open-source, containerized, user-friendly tool that facilitates reproducible analysis of task-based and resting-state fMRI data through uniform application of preprocessing, quality assessment, single-subject feature extraction, and group-level statistics. It provides state-of-the-art preprocessing using fMRIPrep without the requirement for input data in Brain Imaging Data Structure (BIDS) format. HALFpipe extends the functionality of fMRIPrep with additional preprocessing steps, which include spatial smoothing, grand mean scaling, temporal filtering, and confound regression. HALFpipe generates an interactive quality assessment (QA) webpage to rate the quality of key preprocessing outputs and raw data in general. HALFpipe features myriad post-processing functions at the individual subject level, including calculation of task-based activation, seed-based connectivity, network-template (or dual) regression, atlas-based functional connectivity matrices, regional homogeneity (ReHo), and fractional amplitude of low-frequency fluctuations (fALFF), offering support to evaluate a combinatorial number of features or preprocessing settings in one run. Finally, flexible factorial models can be defined for mixed-effects regression analysis at the group level, including multiple comparison correction. Here, we introduce the theoretical framework in which HALFpipe was developed, and present an overview of the main functions of the pipeline. HALFpipe offers the scientific community a major advance toward addressing the reproducibility crisis in neuroimaging, providing a workflow that encompasses preprocessing, post-processing, and QA of fMRI data, while broadening core principles of data analysis for producing reproducible results. Instructions and code can be found at https://github.com/HALFpipe/HALFpipe.},
        language = {en},
        number = {9},
        urldate = {2022-07-14},
        journal = {Human Brain Mapping},
        author = {Waller, Lea and Erk, Susanne and Pozzi, Elena and Toenders, Yara J. and Haswell, Courtney C. and Büttner, Marc and Thompson, Paul M. and Schmaal, Lianne and Morey, Rajendra A. and Walter, Henrik and Veer, Ilya M.},
        year = {2022},
        note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.25829},
        keywords = {fMRI, harmonization, image analysis, meta-analysis pipeline, open source, reproducibility},
        pages = {2727--2742},
        file = {Full Text PDF:C\:\\Users\\Lea\\Zotero\\storage\\5RTPFA9A\\Waller et al. - 2022 - ENIGMA HALFpipe Interactive, reproducible, and ef.pdf:application/pdf;Snapshot:C\:\\Users\\Lea\\Zotero\\storage\\CGJF46TW\\hbm.html:text/html},
}

@article{abraham_machine_2014,
        title = {Machine learning for neuroimaging with scikit-learn},
        volume = {8},
        issn = {1662-5196},
        url = {https://www.frontiersin.org/articles/10.3389/fninf.2014.00014},
        abstract = {Statistical machine learning methods are increasingly used for neuroimaging data analysis. Their main virtue is their ability to model high-dimensional datasets, e.g., multivariate analysis of activation images or resting-state time series. Supervised learning is typically used in decoding or encoding settings to relate brain images to behavioral or clinical observations, while unsupervised learning can uncover hidden structures in sets of images (e.g., resting state functional MRI) or find sub-populations in large cohorts. By considering different functional neuroimaging applications, we illustrate how scikit-learn, a Python machine learning library, can be used to perform some key analysis steps. Scikit-learn contains a very large set of statistical learning algorithms, both supervised and unsupervised, and its application to neuroimaging data provides a versatile tool to study the brain.},
        urldate = {2022-07-14},
        journal = {Frontiers in Neuroinformatics},
        author = {Abraham, Alexandre and Pedregosa, Fabian and Eickenberg, Michael and Gervais, Philippe and Mueller, Andreas and Kossaifi, Jean and Gramfort, Alexandre and Thirion, Bertrand and Varoquaux, Gael},
        year = {2014},
        file = {Full Text PDF:C\:\\Users\\Lea\\Zotero\\storage\\PY9P63AL\\Abraham et al. - 2014 - Machine learning for neuroimaging with scikit-lear.pdf:application/pdf},
}

@misc{phan_composable_2019,
        title = {Composable {Effects} for {Flexible} and {Accelerated} {Probabilistic} {Programming} in {NumPyro}},
        url = {http://arxiv.org/abs/1912.11554},
        doi = {10.48550/arXiv.1912.11554},
        abstract = {NumPyro is a lightweight library that provides an alternate NumPy backend to the Pyro probabilistic programming language with the same modeling interface, language primitives and effect handling abstractions. Effect handlers allow Pyro's modeling API to be extended to NumPyro despite its being built atop a fundamentally different JAX-based functional backend. In this work, we demonstrate the power of composing Pyro's effect handlers with the program transformations that enable hardware acceleration, automatic differentiation, and vectorization in JAX. In particular, NumPyro provides an iterative formulation of the No-U-Turn Sampler (NUTS) that can be end-to-end JIT compiled, yielding an implementation that is much faster than existing alternatives in both the small and large dataset regimes.},
        urldate = {2022-07-14},
        publisher = {arXiv},
        author = {Phan, Du and Pradhan, Neeraj and Jankowiak, Martin},
        month = dec,
        year = {2019},
        note = {arXiv:1912.11554 [cs, stat]},
        keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Programming Languages, G.3, I.2.5, I.2.5, G.3, Statistics - Machine Learning},
        annote = {Comment: 10 pages, 2 figures; NeurIPS 2019 Program Transformations for Machine Learning Workshop},
        file = {arXiv Fulltext PDF:C\:\\Users\\Lea\\Zotero\\storage\\ZHVGLBHX\\Phan et al. - 2019 - Composable Effects for Flexible and Accelerated Pr.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Lea\\Zotero\\storage\\3NHFPD5W\\1912.html:text/html},
}

@article{dockes_neuroquery_2020,
        title = {{NeuroQuery}, comprehensive meta-analysis of human brain mapping},
        volume = {9},
        issn = {2050-084X},
        url = {https://doi.org/10.7554/eLife.53385},
        doi = {10.7554/eLife.53385},
        abstract = {Reaching a global view of brain organization requires assembling evidence on widely different mental processes and mechanisms. The variety of human neuroscience concepts and terminology poses a fundamental challenge to relating brain imaging results across the scientific literature. Existing meta-analysis methods perform statistical tests on sets of publications associated with a particular concept. Thus, large-scale meta-analyses only tackle single terms that occur frequently. We propose a new paradigm, focusing on prediction rather than inference. Our multivariate model predicts the spatial distribution of neurological observations, given text describing an experiment, cognitive process, or disease. This approach handles text of arbitrary length and terms that are too rare for standard meta-analysis. We capture the relationships and neural correlates of 7547 neuroscience terms across 13 459 neuroimaging publications. The resulting meta-analytic tool, neuroquery.org, can ground hypothesis generation and data-analysis priors on a comprehensive view of published findings on the brain.},
        urldate = {2022-07-14},
        journal = {eLife},
        author = {Dockès, Jérôme and Poldrack, Russell A and Primet, Romain and Gözükan, Hande and Yarkoni, Tal and Suchanek, Fabian and Thirion, Bertrand and Varoquaux, Gaël},
        editor = {Büchel, Christian and Yeo, Thomas and Wager, Tor D},
        month = mar,
        year = {2020},
        note = {Publisher: eLife Sciences Publications, Ltd},
        keywords = {brain imaging, cognitive ontologies, meta analysis, predictive models},
        pages = {e53385},
        file = {Full Text PDF:C\:\\Users\\Lea\\Zotero\\storage\\8BST3R9D\\Dockès et al. - 2020 - NeuroQuery, comprehensive meta-analysis of human b.pdf:application/pdf},
}

@techreport{westfall_fixing_2016,
        title = {Fixing the stimulus-as-fixed-effect fallacy in task {fMRI}},
        copyright = {http://creativecommons.org/licenses/by/4.0/},
        url = {https://wellcomeopenresearch.org/articles/1-23},
        abstract = {Most functional magnetic resonance imaging (fMRI) experiments record the brain’s responses to samples of stimulus materials (e.g., faces or words). Yet the statistical modeling approaches used in fMRI research universally fail to model stimulus variability in a manner that affords population generalization, meaning that researchers’ conclusions technically apply only to the precise stimuli used in each study, and cannot be generalized to new stimuli. A direct consequence of this stimulus-as-fixed-effect fallacy is that the majority of published fMRI studies have likely overstated the strength of the statistical evidence they report. Here we develop a Bayesian mixed model (the random stimulus model; RSM) that addresses this problem, and apply it to a range of fMRI datasets. Results demonstrate considerable inflation (50-200\% in most of the studied datasets) of test statistics obtained from standard “summary statistics”-based approaches relative to the corresponding RSM models. We demonstrate how RSMs can be used to improve parameter estimates, properly control false positive rates, and test novel research hypotheses about stimulus-level variability in human brain responses.},
        language = {en},
        number = {1:23},
        urldate = {2022-07-14},
        institution = {Wellcome Open Research},
        author = {Westfall, Jacob and Nichols, Thomas E. and Yarkoni, Tal},
        month = dec,
        year = {2016},
        doi = {10.12688/wellcomeopenres.10298.1},
        note = {Type: article},
        keywords = {Bayesian modeling, experimental design, functional magnetic resonance imaging, mixed-effect modeling, statistical modeling, stimulus-as-fixed-effect fallacy},
        file = {Full Text PDF:C\:\\Users\\Lea\\Zotero\\storage\\SBKEJPVG\\Westfall et al. - 2016 - Fixing the stimulus-as-fixed-effect fallacy in tas.pdf:application/pdf},
}